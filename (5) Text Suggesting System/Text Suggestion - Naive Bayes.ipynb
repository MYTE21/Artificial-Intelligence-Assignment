{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import bigrams,trigrams \n",
    "from nltk.corpus import reuters\n",
    "from collections import Counter, defaultdict\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.corpora import WikiCorpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\gensim\\utils.py:1268: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected %s; aliasing chunkize to chunkize_serial\" % entity)\n"
     ]
    }
   ],
   "source": [
    "dataset_path = datapath('enwiki-latest-pages-articles1.xml-p000000010p000030302-shortened.bz2')\n",
    "wiki_sentences = WikiCorpus(dataset_path).get_texts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object WikiCorpus.get_texts at 0x000001F14B9A43C8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# get Reuters DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('reuters')\n",
    "reuters_sentences  = reuters.sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ASIAN', 'EXPORTERS', 'FEAR', 'DAMAGE', 'FROM', 'U', '.', 'S', '.-', 'JAPAN', 'RIFT', 'Mounting', 'trade', 'friction', 'between', 'the', 'U', '.', 'S', '.', 'And', 'Japan', 'has', 'raised', 'fears', 'among', 'many', 'of', 'Asia', \"'\", 's', 'exporting', 'nations', 'that', 'the', 'row', 'could', 'inflict', 'far', '-', 'reaching', 'economic', 'damage', ',', 'businessmen', 'and', 'officials', 'said', '.'], ['They', 'told', 'Reuter', 'correspondents', 'in', 'Asian', 'capitals', 'a', 'U', '.', 'S', '.', 'Move', 'against', 'Japan', 'might', 'boost', 'protectionist', 'sentiment', 'in', 'the', 'U', '.', 'S', '.', 'And', 'lead', 'to', 'curbs', 'on', 'American', 'imports', 'of', 'their', 'products', '.'], ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_probabilities(sentence_model):\n",
    "  for next_word in sentence_model:\n",
    "    next_words = sentence_model[next_word]\n",
    "    total_word_count = float(sum(next_words.values()))\n",
    "    for previous_word in next_words:\n",
    "      next_words[previous_word]/=total_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sigle_word_probability(sentence_model,word_count):\n",
    "  for word in sentence_model:\n",
    "    sentence_model[word]/=word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_lower(pa):\n",
    "  if type(pa)==str:\n",
    "    return pa.lower()\n",
    "  return pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_model4 = defaultdict(lambda: set())\n",
    "sentence_model5 = defaultdict(lambda: set())\n",
    "\n",
    "def calculate_word_count(sentence_model1,sentence_model2,sentence_model3,sentences):\n",
    "  word_count = 0\n",
    "  for sentence in sentences:\n",
    "    for word in sentence:\n",
    "      word_count += 1\n",
    "      sentence_model1[word] += 1\n",
    "    for previous_word2, previous_word1, next_word in trigrams(sentence, pad_right=True, pad_left=True):\n",
    "      previous_word1 = convert_to_lower(previous_word1)\n",
    "      previous_word2 = convert_to_lower(previous_word2)\n",
    "      next_word = convert_to_lower(next_word)\n",
    "      sentence_model2[next_word][previous_word1] += 1\n",
    "      sentence_model3[next_word][previous_word2] += 1\n",
    "      sentence_model4[previous_word1].add(next_word)\n",
    "      sentence_model5[previous_word2].add(next_word)\n",
    "\n",
    "  return word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_model1 = defaultdict(lambda:0)\n",
    "sentence_model2 = defaultdict(lambda: defaultdict(lambda:0))\n",
    "sentence_model3 = defaultdict(lambda: defaultdict(lambda:0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_word_count = calculate_word_count(sentence_model1,sentence_model2,sentence_model3,wiki_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "452944"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reuters_word_count = calculate_word_count(sentence_model1, sentence_model2, sentence_model3, reuters_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1720917"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_probabilities(sentence_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_probabilities(sentence_model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_word = wiki_word_count + reuters_word_count\n",
    "calculate_sigle_word_probability(sentence_model1, total_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_probability_words = []\n",
    "\n",
    "def make_word_suggestion_by_trigram(previous_word2, previous_word1):\n",
    "  for next_word in sentence_model4[previous_word1] & sentence_model5[previous_word2]:\n",
    "    naiveBias_trigram_weight = sentence_model1[next_word] * sentence_model2[next_word][previous_word1]*sentence_model3[next_word][previous_word2]\n",
    "    max_probability_words.append((next_word, naiveBias_trigram_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_word_suggestion_by_trigram('my','name')\n",
    "max_probability_words.sort(key=lambda o:o[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('is', 2.684929364088014e-08) ('to', 1.1753701280369164e-09) (',', 5.59438489695973e-10) ('in', 4.6278217257881707e-10) ('and', 4.5063509855288127e-10) ('for', 3.738790783749001e-10) ('would', 3.5383441884561533e-10) ('will', 2.8735045390861837e-10) ('that', 2.0690529880634479e-10) ('or', 1.711572663102755e-10)\n"
     ]
    }
   ],
   "source": [
    "print(*max_probability_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your line: i am\n",
      "('afraid', 1.0350247784931974e-06) ('sure', 8.036310732474202e-07) ('astonished', 4.600110126636432e-07) ('speculating', 3.6800881013091455e-07) ('deeply', 1.8818632336239947e-07) ('convinced', 1.5333700422121436e-07) ('confident', 1.2893042223444673e-07) ('inclined', 4.600110126636432e-08) ('hopeful', 4.600110126636432e-08) ('sceptical', 3.833425105530359e-08)\n",
      "Enter your line: do you\n",
      "('want', 1.457018352093729e-07) ('have', 7.580336901109201e-08) ('think', 2.6624154551874957e-08) ('look', 2.3725843203914056e-08) ('need', 2.1517623247651324e-08) ('know', 1.9034938455047303e-08) (\"'\", 1.2241932387039204e-08) ('see', 8.059507073354229e-09) ('could', 7.793242782937693e-09) ('make', 5.675392260577992e-09)\n",
      "Enter your line: this is\n",
      "('not', 2.067997280891107e-06) ('the', 9.009376019611534e-07) ('expected', 7.882243308937478e-07) ('due', 7.304506050183651e-07) ('also', 7.127958871912021e-07) ('a', 5.638395931369035e-07) ('likely', 4.876159326203692e-07) ('conspicuous', 4.600110126636432e-07) ('amore', 4.600110126636432e-07) ('often', 4.566695283101542e-07)\n",
      "Enter your line: bangladesh is\n",
      "('nominally', 6.571585895194902e-08) ('an', 2.7933336734722146e-08) ('no', 2.7441100252514623e-08) ('awarded', 9.018939567956929e-09) ('a', 7.322592118661084e-09) ('the', 3.647520655713172e-09) ('on', 2.234686395822939e-09) ('for', 1.6450679448495607e-09) ('cut', 8.565888110322454e-10) ('of', 5.069108054289822e-10)\n",
      "Enter your line: i go to\n",
      "('to', 6.713714171346866e-09) ('out', 3.3238317313472445e-09) ('it', 2.4526530626636454e-09) ('no', 2.0632406204898215e-09) ('down', 1.7354133853340337e-09) (',\"', 1.3541684211470215e-09) ('against', 1.0375254089094743e-09) ('on', 8.289965661923805e-10) ('for', 8.225339724247801e-10) ('much', 6.18066963909117e-10)\n",
      "Enter your line: as if\n",
      "('the', 5.001359402036547e-07) ('they', 1.928760608023679e-07) ('necessary', 1.3324727699985045e-07) ('there', 8.529731650222074e-08) ('it', 7.795932949180875e-08) ('any', 7.227028576470174e-08) ('you', 5.0259778129560773e-08) ('defendant', 4.3810572634632676e-08) ('that', 3.5877378813020186e-08) ('screening', 3.538546251258794e-08)\n",
      "Enter your line: stop\n",
      "The Program Stopped.....\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    text = input(\"Enter your line: \")\n",
    "    if text == \"stop\":\n",
    "        print(\"The Program Stopped.....\")\n",
    "        break\n",
    "    \n",
    "    else:\n",
    "        try:\n",
    "            max_probability_words = []\n",
    "            text = text.split(\" \")\n",
    "            make_word_suggestion_by_trigram(text[0],text[1])\n",
    "            max_probability_words.sort(key=lambda o:o[1],reverse=True)\n",
    "            print(*max_probability_words[:10])\n",
    "            \n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
