{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import bigrams,trigrams \n",
    "from nltk.corpus import reuters\n",
    "from collections import Counter, defaultdict\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.corpora import WikiCorpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = datapath('enwiki-latest-pages-articles1.xml-p000000010p000030302-shortened.bz2')\n",
    "wiki_sentences = WikiCorpus(dataset_path).get_texts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object WikiCorpus.get_texts at 0x0000018A9B47DC48>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# get Reuters DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('reuters')\n",
    "reuters_sentences  = reuters.sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ASIAN', 'EXPORTERS', 'FEAR', 'DAMAGE', 'FROM', 'U', '.', 'S', '.-', 'JAPAN', 'RIFT', 'Mounting', 'trade', 'friction', 'between', 'the', 'U', '.', 'S', '.', 'And', 'Japan', 'has', 'raised', 'fears', 'among', 'many', 'of', 'Asia', \"'\", 's', 'exporting', 'nations', 'that', 'the', 'row', 'could', 'inflict', 'far', '-', 'reaching', 'economic', 'damage', ',', 'businessmen', 'and', 'officials', 'said', '.'], ['They', 'told', 'Reuter', 'correspondents', 'in', 'Asian', 'capitals', 'a', 'U', '.', 'S', '.', 'Move', 'against', 'Japan', 'might', 'boost', 'protectionist', 'sentiment', 'in', 'the', 'U', '.', 'S', '.', 'And', 'lead', 'to', 'curbs', 'on', 'American', 'imports', 'of', 'their', 'products', '.'], ...]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_probabilities(sentence_model):\n",
    "  for next_word in sentence_model:\n",
    "    next_words = sentence_model[next_word]\n",
    "    total_word_count = float(sum(next_words.values()))\n",
    "    for previous_word in next_words:\n",
    "      next_words[previous_word]/=total_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sigle_word_probability(sentence_model,word_count):\n",
    "  for word in sentence_model:\n",
    "    sentence_model[word]/=word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_lower(pa):\n",
    "  if type(pa)==str:\n",
    "    return pa.lower()\n",
    "  return pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_model4 = defaultdict(lambda: set())\n",
    "sentence_model5 = defaultdict(lambda: set())\n",
    "\n",
    "def calculate_word_count(sentence_model1,sentence_model2,sentence_model3,sentences):\n",
    "  word_count = 0\n",
    "  for sentence in sentences:\n",
    "    for word in sentence:\n",
    "      word_count += 1\n",
    "      sentence_model1[word] += 1\n",
    "    for previous_word2, previous_word1, next_word in trigrams(sentence, pad_right=True, pad_left=True):\n",
    "      previous_word1 = convert_to_lower(previous_word1)\n",
    "      previous_word2 = convert_to_lower(previous_word2)\n",
    "      next_word = convert_to_lower(next_word)\n",
    "      sentence_model2[next_word][previous_word1] += 1\n",
    "      sentence_model3[next_word][previous_word2] += 1\n",
    "      sentence_model4[previous_word1].add(next_word)\n",
    "      sentence_model5[previous_word2].add(next_word)\n",
    "\n",
    "  return word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_model1 = defaultdict(lambda:0)\n",
    "sentence_model2 = defaultdict(lambda: defaultdict(lambda:0))\n",
    "sentence_model3 = defaultdict(lambda: defaultdict(lambda:0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_word_count = calculate_word_count(sentence_model1,sentence_model2,sentence_model3,wiki_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "452944"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "reuters_word_count = calculate_word_count(sentence_model1, sentence_model2, sentence_model3, reuters_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1720917"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_probabilities(sentence_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_probabilities(sentence_model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_word = wiki_word_count + reuters_word_count\n",
    "calculate_sigle_word_probability(sentence_model1, total_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_probability_words = []\n",
    "\n",
    "def make_word_suggestion_by_trigram(previous_word2, previous_word1):\n",
    "  for next_word in sentence_model4[previous_word1] & sentence_model5[previous_word2]:\n",
    "    naiveBias_trigram_weight = sentence_model1[next_word] * sentence_model2[next_word][previous_word1]*sentence_model3[next_word][previous_word2]\n",
    "    max_probability_words.append((next_word, naiveBias_trigram_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_word_suggestion_by_trigram('my','name')\n",
    "max_probability_words.sort(key=lambda o:o[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('is', 2.684929364088014e-08) ('to', 1.1753701280369164e-09) (',', 5.59438489695973e-10) ('in', 4.6278217257881707e-10) ('and', 4.5063509855288127e-10) ('for', 3.738790783749001e-10) ('would', 3.5383441884561533e-10) ('will', 2.8735045390861837e-10) ('that', 2.0690529880634479e-10) ('or', 1.711572663102755e-10)\n"
     ]
    }
   ],
   "source": [
    "print(*max_probability_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your line: go to\n",
      "('the', 5.540810603048347e-07) ('go', 3.8299494667680125e-07) ('sell', 2.6532711001692346e-07) ('settle', 2.5319006137006924e-07) ('bring', 2.3749859383542032e-07) ('a', 1.2340368357350155e-07) ('do', 1.1895936962643927e-07) ('slow', 1.0666801915194969e-07) ('strike', 7.78095691160883e-08) ('10', 6.066503904930029e-08)\n",
      "Enter your line: bangladesh is\n",
      "('nominally', 6.571585895194902e-08) ('an', 2.7933336734722146e-08) ('no', 2.7441100252514623e-08) ('awarded', 9.018939567956929e-09) ('a', 7.322592118661084e-09) ('the', 3.647520655713172e-09) ('on', 2.234686395822939e-09) ('for', 1.6450679448495607e-09) ('cut', 8.565888110322454e-10) ('of', 5.069108054289822e-10)\n",
      "Enter your line: i am\n",
      "('afraid', 1.0350247784931974e-06) ('sure', 8.036310732474202e-07) ('astonished', 4.600110126636432e-07) ('speculating', 3.6800881013091455e-07) ('deeply', 1.8818632336239947e-07) ('convinced', 1.5333700422121436e-07) ('confident', 1.2893042223444673e-07) ('inclined', 4.600110126636432e-08) ('hopeful', 4.600110126636432e-08) ('sceptical', 3.833425105530359e-08)\n",
      "Enter your line: why you\n",
      "('cannot', 1.5856039804193656e-08) ('acted', 1.3517311666883915e-08) ('need', 1.0758811623825662e-08) ('should', 9.19366443348696e-09) ('could', 5.195495188625129e-09) ('have', 5.0535579340728e-09) ('move', 1.731351004865988e-09) ('put', 1.1755129063219136e-09) ('are', 1.0778457064429816e-09) ('might', 9.684051140981786e-10)\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    text = input(\"Enter your line: \")\n",
    "    if text == \"stop\":\n",
    "        print(\"The Program Stopped.....\")\n",
    "        break\n",
    "    \n",
    "    else:\n",
    "        try:\n",
    "            max_probability_words = []\n",
    "            text = text.split(\" \")\n",
    "            make_word_suggestion_by_trigram(text[0],text[1])\n",
    "            max_probability_words.sort(key=lambda o:o[1],reverse=True)\n",
    "            print(*max_probability_words[:10])\n",
    "            \n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
